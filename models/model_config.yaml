ollama_model: mistral
temperature: 0.7
max_tokens: 1024
local: true
embedding_model: all-MiniLM-L6-v2
